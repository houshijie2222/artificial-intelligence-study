 ```python
import os
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
import torch
from torch import nn
import torch.optim as optim
import torchvision
#pip install torchvision
from torchvision import transforms, models, datasets  # transforms包：数据量少需要做数据增强策略 ｜ models：用人家现成的模型和训练参数，进行二次加工，例如只改全连接层， 
#https://pytorch.org/docs/stable/torchvision/index.html
import imageio
import time
import warnings
warnings.filterwarnings("ignore")
import random
import sys
import copy
import json
from PIL import Image
``` 
## 读取数据与预处理操作
数据源是按照文件夹分组放入磁盘的，
```python
data_dir = './flower_data/'
train_dir = data_dir + '/train'
valid_dir = data_dir + '/valid'
```


# 第一步： 制作好数据源：
```python
data_transforms = {
    'train':  # 训练集的数据 ， 用transforms进行数组增强，因为训练数据量较少，通过旋转、剪裁、反转等操作将数据丰富
        transforms.Compose([           # 组合，按顺序组合每一个操作
        transforms.Resize([96, 96]),   # 重设图片大小， 因为数据源等图像大小都不一样，在做数据输入的时候必须得大小一样！ 所以要将所有图重新设置统一的大小，为什么这里用的96 因为小训练的时候 跑得快, 一般用256 512
        # 什么叫数据增强： 一张图经过 平移、旋转、对称等操作变成多张图，让数据通过变换，更具多样性
        transforms.RandomRotation(45),          # 数据增强之：随机旋转，-45到45度之间随机选，这样可以增加训练数据的多样性
        transforms.CenterCrop(64),              # 数据增强之：裁剪，从中心开始裁剪，裁剪后可能图不完整，这样也增加了训练数据的多样性
        transforms.RandomHorizontalFlip(p=0.5), # 数据增强之：随机水平翻转 选择一个概率概率，p=0.5 50%的概率翻转  增加训练数据多样性
        transforms.RandomVerticalFlip(p=0.5),   # 数据增强之：随机垂直翻转，选择一个概率概率，p=0.5 50%的概率翻转  增加训练数据多样性 
        transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1),#参数1为亮度，参数2为对比度，参数3为饱和度，参数4为色相， 一般不改，切割旋转平移做得多，但在极端光照条件下，特暗特亮的才会调整
        transforms.RandomGrayscale(p=0.025),    #概率转换成灰度率，3通道就是R=G=B。  彩色图转成灰度图
        transforms.ToTensor(),  # 将数据 转为tensor结构，
                    #参数对应    R     G      B    由于我们的训练集数据量少，算出来的标准差可能不准，所以用人家同类型的(花)上亿训练数据的标准差   x-U/a
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])# 对数据做标准化， 均值，标准差。， RGB做标准化操作，减去标准差 
    ]),
    'valid':  # 验证集的数据
        transforms.Compose([   # 组合，按顺序组合每一个操作
        transforms.Resize([64, 64]),  # 训练数据最后是多少  验证集也是多少   因为训练的时候CenterCrop是64
        transforms.ToTensor(),    # 转为tensor结构
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #RGB做标准化操作，减去标准差，  验证数据和训练数据的标准化参数 要一致 
    ]),
}
# 设置处理数据的batch大小， 128比较大是因为我们每张图最后是64比较小，要根据显存和数据大小决定batch的大小
batch_size = 128 
# datasets.ImageFolder 以文件夹的形势读取图片， os.path.join(data_dir, x)将两个路径拼接  data_transforms[x]就是上面定义的数据增强策略
# image_datasets的结构就是 [{train数据集，train数据增强transforms},{valid数据集、valid标准化后数据}]
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid']} 
# dataLoader 数据加载，通过dataLoadr加载上面ImageFolder度取到的数据 ，batch_size设置，shuffle设置
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) for x in ['train', 'valid']}
# 计算训练集 和 验证集  有多少个， 这个是为了后面计算  对了多少个 的 准确率的
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']} # 计算 训练集 验证集 有多少数据
class_names = image_datasets['train'].classes # 这里是获取每一个类别的名字  因为我们的数据是按照类别放到一个个文件夹，文件夹有名字1，2，3，4等 class_names对应1，2，3，4

#读取标签对应的实际名字 为了方便后续展示用的， cat_to_name.json存放的是 1:黄菊花 2:紫罗兰这样的数据， 通过上面的1234 找到对应的花名
with open('cat_to_name.json', 'r') as f:  
    cat_to_name = json.load(f)    
```
第一步数据处理结果 

#  第二步：制作模型
加载models中提供的模型，并且直接用训练的好权重当做初始化参数
```python
model_name = 'resnet'  #可选的比较多 ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception']
#是否用人家训练好的特征来做, 就是用人家训练好的权重参数来初始化咱的模型    这就是预训练模型 迁移学习，如果从0开始会很难,在别人练好的基础上修一修改一改会很快效果会很好，微调～     backbone特征提取器，resnet就是backbone特征提取器的一种
feature_extract = True # 都用人家特征，咱先不更新，   feature_extract=True就是自己的训练数据量比较少 ， 冻住前面的网络层 模型参数，不做任何更新
```
#### 迁移学习：
如果所有的都从0开始会很困难，所以要抄人家的，在别的人基础上改改就是迁移学习， 如果随机初始化模型参数可能效果会很差，如果在别人训练好的模型基础上做微调可能效果会很好
1. 预训练模型和参数 都用开源的， 用人家训练好的参数 当作我们的初始化。 在预训练模型的基础上做微调 效果会很好
2. 训练数据的微调，  
    - 自己的训练数据量比较少 ， 冻住前面的网络层 模型参数，只更新输出层  防止越学越差
    - 自己的训练数据量比较中等 ， 冻住少一点网络层 模型参数，
    - 自己的训练数据量比较大 ， 只做 初始化权重参数 ，每一层都训练更新参数
- 总之： 输出层得自己练， 其他层看训练的数据量定
#  第三步： 选择用 cpu 还是 gpu 去跑这个模型
```python
# 是否用GPU训练, 根据系统配置判断是用GPU训练还是用CPU训练
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')
    
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
```
# 第四步：设置模型，从torch包里选一个合适模型，在人家的基础上去做
```python
def set_parameter_requires_grad(model, feature_extracting): 
    if feature_extracting:
        for param in model.parameters():    # 用人家的模型，用人家的模型参数，初始化，  遍历我们选的这个模型的全部权重参数，并且设置 requires_grad = False 每个参数都是False 都不做改变，相当于冻住了。  requires_grad其实就是设置要不要 反向传播要不要计算梯度，没有梯度肯定就没法改他的参数了
            param.requires_grad = False    # requires_grad反向传播要不要计算梯度，不计算梯度就没法修改原来的参数了
# 从torch的model包里选一个模型出来，18是18层网络层的，他会快一点，但效果可能没有层数多的好
model_ft = models.resnet18()#18层的能快点，条件好点的也可以选152
model_ft  #看一下我们选的模型的 网络层的一些参数
```
ResNet( 
        2d的卷积，输入是3 输出是64，卷积核的大小是7*7， stride步长是2， padding参数 变原来一样的大小
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
         标准化.....
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  .....
   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))             池化降纬度
  (fc): Linear(in_features=512, out_features=1000, bias=True)   输出的时候人家是1000分类，这个要改成我们数据集的102分类
)
### 把模型输出层改成自己的
```python
def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):
    
    model_ft = models.resnet18(pretrained=use_pretrained)   # pretrained=True 的意思是用预模型训练好的参数作为我们模型的初始化参数，  他会自动下载
    set_parameter_requires_grad(model_ft, feature_extract)  # 把模型中 所有的requires_grad 都设置成False，模型参数不更新 冻住了
    
    num_ftrs = model_ft.fc.in_features  # 512 找到预训练模型网络层的最后一次输出 也就是全连接层的入参，  因为我们要把模型的输出层变成自己的，就是改成自己的全连接层
    model_ft.fc = nn.Linear(num_ftrs, 102)#类别数自己根据自己任务来 ， 定义自己的全连接层， 输入是上面得到的网络层最后一次输出512，输出是102， 102分类就是102
                            
    input_size = 64#输入大小根据自己配置来， 

    return model_ft, input_size
```
### 设置哪些层需要训练
```python
                                       # model_name = resnet ，分类的类别数量是102， feature_extract是True，    use_pretrained 使用与训练型                
model_ft, input_size = initialize_model(model_name, 102, feature_extract, use_pretrained=True) # 初始化模型
 
#GPU还是CPU计算去 算
model_ft = model_ft.to(device)

# 模型保存，名字自己起
filename='checkpoint.pth'

# 是否训练所有层,   网络层不算梯度，但输出全连接层要计算梯度，优化参数 权重和偏执
params_to_update = model_ft.parameters() #parameters获取到所有的参数
print("Params to learn:")
if feature_extract: 
    params_to_update = []
    for name,param in model_ft.named_parameters():
        if param.requires_grad == True:
            params_to_update.append(param)
            print("\t",name)
else:
    for name,param in model_ft.named_parameters():
        if param.requires_grad == True:
            print("\t",name)
```

# 优化器
```python
# 优化器设置
                    # 优化器，params_to_update是 全连接层的参数，因为网络层冻住了，lr学习率
optimizer_ft = optim.Adam(params_to_update, lr=1e-2)#要训练啥参数，你来定      Adam 力的合成方向， lr学习率，  
scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)#学习率每7个epoch衰减成原来的1/10，  这里的学习率会适度衰减， 因为随着迭代次数增加 学习率会越来越缓    ， 就快接近正确答案了肯定要缓慢一点， StepLR就是设置学习率的衰减策略， 参数1是优化器、参数2 迭代10次epoch执行一次学习率衰减，参数3是 学习率变成原来的1/10
criterion = nn.CrossEntropyLoss()
```

### 训练模块
```python
def train_model(model, dataloaders, criterion, optimizer, num_epochs=25,filename='best.pt'):
    #咱们要算时间的
    since = time.time()
    #也要记录最好的那一次，  因为验证集不一定会随着迭代次数增加一直变好，所以要根据每一次迭代验证集的结果 判断 哪一次最好就保存哪一次
    best_acc = 0
    #模型也得放到你的CPU或者GPU
    model.to(device)
    #训练过程中打印一堆损失和指标
    val_acc_history = []
    train_acc_history = []
    train_losses = []
    valid_losses = []
    #学习率
    LRs = [optimizer.param_groups[0]['lr']]         #取当前的学习率
    #最好的那次模型，后续会变的，先初始化
    best_model_wts = copy.deepcopy(model.state_dict())
    #一个个epoch来遍历
    for epoch in range(num_epochs):  
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        # 训练和验证
        for phase in ['train', 'valid']:     # 训练集和验证集都需要遍历，进行前向传播， 只不过训练集还需要进行反向传播和参数更新 所以就写到一起了
            if phase == 'train':
                model.train()  # 训练
            else:
                model.eval()   # 验证

            running_loss = 0.0
            running_corrects = 0

            # 把数据都取个遍，遍历完dataloader 是一次epoch， 每一次迭代item都计算了损失 和 准确率
            for inputs, labels in dataloaders[phase]:     #epoch一次可能要很多次迭代
                inputs = inputs.to(device)#放到你的CPU或GPU
                labels = labels.to(device)

                # 梯度清零
                optimizer.zero_grad()
                # 只有训练的时候计算和更新梯度
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                _, preds = torch.max(outputs, 1)
                # 训练阶段更新权重
                if phase == 'train':
                    loss.backward()  # 反向传播
                    optimizer.step() # 参数更新

                # 计算损失，正确数  。  每一次迭代item都计算 损失 和 预测正确的个数  并把它们累加起来 如下
                running_loss += loss.item() * inputs.size(0)#0表示batch那个维度
                running_corrects += torch.sum(preds == labels.data)#预测结果最大的和真实值是否一致
                
            
            # 经过多次迭代，跑完一次数据集即一次epoch， 求平均的损失和准确率
            epoch_loss = running_loss / len(dataloaders[phase].dataset)#算平均   ，把所有迭代的损失算出来 /次数 得到 平均损失
            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)  # 
            
            time_elapsed = time.time() - since  #一个epoch我使用了多长时间
            print('Time elapsed {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))
            

            # 得到最好那次的模型   ，判断是训练集 且 当前的准确率 大于 目前最好一次的准确率， 如果当前准确率更高
            if phase == 'valid' and epoch_acc > best_acc:  # 如果 当前验证集的结果 比 之前最好的 还强的话，就保存当前的权重参数，
                best_acc = epoch_acc 
                best_model_wts = copy.deepcopy(model.state_dict()) #将当前的参数 进行替换
                state = {           
                  'state_dict': model.state_dict(),#字典里key就是各层的名字，值就是训练好的权重
                  'best_acc': best_acc,
                  'optimizer' : optimizer.state_dict(),
                }
                torch.save(state, filename) #保存
            if phase == 'valid':
                val_acc_history.append(epoch_acc)
                valid_losses.append(epoch_loss)
                #scheduler.step(epoch_loss)#学习率衰减
            if phase == 'train':
                train_acc_history.append(epoch_acc)
                train_losses.append(epoch_loss)
        
        print('Optimizer learning rate : {:.7f}'.format(optimizer.param_groups[0]['lr']))
        LRs.append(optimizer.param_groups[0]['lr']) #把学习率保存下来
        print()
        scheduler.step()#学习率衰减， 调用我们前面定义好的衰减器，每十次学习率衰减为原来的1/10

    time_elapsed = time.time() - since 
    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
    print('Best val Acc: {:4f}'.format(best_acc))

    # 训练完后用最好的一次当做模型最终的结果,等着一会测试
    model.load_state_dict(best_model_wts)
    return model, val_acc_history, train_acc_history, valid_losses, train_losses, LRs 
```

### 开始训练
```python
model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs  = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=20)
```
训练过程中打印的结果  
Epoch 0/19
----------
Time elapsed 1m 41s             # 耗时
train Loss: 2.8780 Acc: 0.4626  # 训练集 损失
Time elapsed 1m 49s             # 耗时 
valid Loss: 4.4357 Acc: 0.3068  # 验证集 损失 和 准确率
Optimizer learning rate : 0.0100000

Epoch 1/19
----------
Time elapsed 3m 26s
train Loss: 2.7172 Acc: 0.4841
Time elapsed 3m 33s
valid Loss: 4.4957 Acc: 0.3130   # 验证集 损失 和 准确率
Optimizer learning rate : 0.0100000

Epoch 2/19
----------
Time elapsed 5m 10s
train Loss: 2.9039 Acc: 0.4689
Time elapsed 5m 18s
valid Loss: 4.3735 Acc: 0.3374
Optimizer learning rate : 0.0100000

Epoch 3/19
----------
Time elapsed 6m 55s
train Loss: 2.8944 Acc: 0.4751
Time elapsed 7m 3s
valid Loss: 4.6739 Acc: 0.3325
Optimizer learning rate : 0.0100000

Epoch 4/19
----------
Time elapsed 8m 41s
train Loss: 2.8220 Acc: 0.4928
Time elapsed 8m 49s
valid Loss: 4.5819 Acc: 0.3509
Optimizer learning rate : 0.0100000

Epoch 5/19
----------
Time elapsed 10m 29s
train Loss: 2.9199 Acc: 0.4826
Time elapsed 10m 37s
valid Loss: 4.6525 Acc: 0.3386
Optimizer learning rate : 0.0100000

Epoch 6/19
----------
Time elapsed 12m 16s
train Loss: 2.9077 Acc: 0.4847
Time elapsed 12m 24s
valid Loss: 4.9548 Acc: 0.3032
Optimizer learning rate : 0.0100000

Epoch 7/19
----------
Time elapsed 46m 23s
train Loss: 2.8932 Acc: 0.4890
Time elapsed 46m 31s
valid Loss: 4.9844 Acc: 0.3105
Optimizer learning rate : 0.0100000

Epoch 8/19
----------
Time elapsed 79m 53s
train Loss: 2.8885 Acc: 0.4864
Time elapsed 80m 1s
valid Loss: 4.6786 Acc: 0.3509
Optimizer learning rate : 0.0100000

Epoch 9/19
----------
Time elapsed 90m 13s
train Loss: 2.8499 Acc: 0.4899
Time elapsed 90m 21s
valid Loss: 4.7439 Acc: 0.3289
Optimizer learning rate : 0.0100000

Epoch 10/19
----------
Time elapsed 91m 59s
train Loss: 2.3892 Acc: 0.5397
Time elapsed 92m 7s
valid Loss: 4.2194 Acc: 0.3680
Optimizer learning rate : 0.0010000  #第10次epoch的时候 学习率变成原来的1/10

Epoch 11/19
----------
Time elapsed 93m 45s
train Loss: 2.2528 Acc: 0.5530
Time elapsed 93m 53s
valid Loss: 4.1424 Acc: 0.3570
Optimizer learning rate : 0.0010000

Epoch 12/19
----------
Time elapsed 95m 31s
train Loss: 2.1193 Acc: 0.5635
Time elapsed 95m 39s
valid Loss: 4.1203 Acc: 0.3557
Optimizer learning rate : 0.0010000

Epoch 13/19
----------
Time elapsed 97m 18s
train Loss: 2.0657 Acc: 0.5681
Time elapsed 97m 25s
valid Loss: 4.1575 Acc: 0.3606
Optimizer learning rate : 0.0010000

Epoch 14/19
----------
Time elapsed 99m 7s
train Loss: 2.0085 Acc: 0.5702
Time elapsed 99m 14s
valid Loss: 4.1089 Acc: 0.3594
Optimizer learning rate : 0.0010000

Epoch 15/19
----------
Time elapsed 100m 53s
train Loss: 2.0065 Acc: 0.5760
Time elapsed 101m 0s
valid Loss: 3.9593 Acc: 0.3753    # 最高的一次 准确率达到0.375
Optimizer learning rate : 0.0010000

Epoch 16/19
----------
Time elapsed 102m 38s
train Loss: 1.9561 Acc: 0.5728
Time elapsed 102m 45s
valid Loss: 4.0211 Acc: 0.3643
Optimizer learning rate : 0.0010000

Epoch 17/19
----------
Time elapsed 104m 22s
train Loss: 1.9383 Acc: 0.5809
Time elapsed 104m 30s
valid Loss: 3.9312 Acc: 0.3631
Optimizer learning rate : 0.0010000

Epoch 18/19
----------
Time elapsed 106m 7s
train Loss: 1.9351 Acc: 0.5812
Time elapsed 106m 15s
valid Loss: 3.8891 Acc: 0.3692
Optimizer learning rate : 0.0010000

Epoch 19/19
----------
Time elapsed 107m 52s
train Loss: 1.9267 Acc: 0.5798
Time elapsed 107m 60s
valid Loss: 3.8577 Acc: 0.3692        
Optimizer learning rate : 0.0010000

Training complete in 107m 60s
Best val Acc: 0.375306       #最后只保留最好的那一次的参数



- 前面通过冻住网络层，并随即初始化全连接输出层，来训练一个全连层， 现在全连接层油了一个还可以的参数集， 就在进行一次整体的训练
# 进行第二轮所有层的训练
```python
for param in model_ft.parameters():
    # 遍历模型中所有的参数 的requires_grad设置成True，这样每一层都会做反向传播和优化参数
    param.requires_grad = True

# 再继续训练所有的参数，学习率调小一点 ， 这次优化器传入的是所有的参数，
optimizer = optim.Adam(model_ft.parameters(), lr=1e-3)
scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

# 损失函数
criterion = nn.CrossEntropyLoss()
```

```python
# 加载之前训练好的权重参数
checkpoint = torch.load(filename)  # fileName 是前面预训练的时候训练好的模型参数 导出的文件
best_acc = checkpoint['best_acc']
model_ft.load_state_dict(checkpoint['state_dict'])
# 再训练后 查看结果
model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs  = train_model(model_ft, dataloaders, criterion, optimizer, num_epochs=10,)
```





# 开始验证
```python
model_ft, input_size = initialize_model(model_name, 102, feature_extract, use_pretrained=True)

# GPU模式
model_ft = model_ft.to(device)

# 保存文件的名字,模型名字
filename='best.pt'

# 加载模型
checkpoint = torch.load(filename)
best_acc = checkpoint['best_acc']
model_ft.load_state_dict(checkpoint['state_dict'])

# 加载并处理 测试的数据  得到一个batch的测试数据
dataiter = iter(dataloaders['valid'])
images, labels = dataiter.next()

model_ft.eval()

# 测试数据放入模型中
if train_on_gpu:
    output = model_ft(images.cuda())
else:
    output = model_ft(images)

# 得到结果， 通过模型输出的概率 获取到最大的那个概率就认为是那个分类，
_, preds_tensor = torch.max(output, 1)
# 将数据转为可以画图的数据格式，                                                   # 将gpu数据转为cpu数据再转位nuumpy格式
preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())
preds  # 打印测试集的 类别

def im_convert(tensor):
    """ 展示数据"""
    
    image = tensor.to("cpu").clone().detach()
    image = image.numpy().squeeze()
    image = image.transpose(1,2,0)  # 换一下位置， 将3*64*64 格式的 channel、length、heigh、换成 64*64*3 把channel换到最后一位
    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))  # 数值还原， y = (x-a)/b   x= y*b +a 
    image = image.clip(0, 1)

    return image
```

